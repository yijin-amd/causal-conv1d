# å¿«é€Ÿå¼€å§‹æŒ‡å— - Causal Conv1D HIP

## ğŸš€ 5åˆ†é’Ÿå¿«é€Ÿä¸Šæ‰‹

### 1. ç¼–è¯‘æ‰©å±•

```bash
cd /workspace/causal-conv1d/rocm_backend/causal_conv1d_hip
./compile_hip_extension.sh
```

### 2. è®¾ç½®ç¯å¢ƒå˜é‡

```bash
export PYTHONPATH=$PWD/build:$PYTHONPATH
```

### 3. è¿è¡Œç¤ºä¾‹

```bash
python3 example_usage.py
```

## ğŸ“ æœ€å°ä»£ç ç¤ºä¾‹

```python
import torch
from causal_conv1d_hip_interface import causal_conv1d_hip_fn

# åˆ›å»ºæ•°æ®
x = torch.randn(2, 64, 512, device='cuda')
weight = torch.randn(64, 4, device='cuda')
bias = torch.randn(64, device='cuda')

# è¿è¡Œ
out = causal_conv1d_hip_fn(x, weight, bias, activation='silu')
```

## ğŸ“‹ ä¸ CUDA ç‰ˆæœ¬å¯¹æ¯”

| ç‰¹æ€§ | CUDA ç‰ˆæœ¬ | HIP ç‰ˆæœ¬ |
|-----|----------|---------|
| Python æ¥å£ | `causal_conv1d_fn` | `causal_conv1d_hip_fn` |
| å‰å‘ä¼ æ’­ | âœ… æ”¯æŒ | âœ… æ”¯æŒ |
| åå‘ä¼ æ’­ | âœ… æ”¯æŒ | âŒ æœªå®ç° |
| FP16/BF16 | âœ… æ”¯æŒ | âŒ ä»… FP32 |
| Channel-Last | âœ… æ”¯æŒ | âŒ ä»… Channel-First |
| seq_idx | âœ… æ”¯æŒ | âŒ æœªå®ç° |
| initial/final states | âœ… æ”¯æŒ | âŒ æœªå®ç° |

## ğŸ”§ API å¯¹ç…§

### CUDA ç‰ˆæœ¬

```python
from causal_conv1d import causal_conv1d_fn

out = causal_conv1d_fn(
    x,                      # (batch, dim, seqlen)
    weight,                 # (dim, width)
    bias,                   # (dim,)
    seq_idx=None,           # (batch, seqlen)
    initial_states=None,    # (batch, dim, width-1)
    return_final_states=False,
    final_states_out=None,
    activation='silu'
)
```

### HIP ç‰ˆæœ¬

```python
from causal_conv1d_hip_interface import causal_conv1d_hip_fn

out = causal_conv1d_hip_fn(
    x,                      # (batch, dim, seqlen)
    weight,                 # (dim, width)
    bias,                   # (dim,)
    activation='silu'       # None, 'silu', or 'swish'
)
```

## âš™ï¸ é…ç½®é€‰é¡¹

### Width æ”¯æŒ

```python
# Width = 2
weight = torch.randn(dim, 2, device='cuda')
out = causal_conv1d_hip_fn(x, weight, bias)

# Width = 3
weight = torch.randn(dim, 3, device='cuda')
out = causal_conv1d_hip_fn(x, weight, bias)

# Width = 4
weight = torch.randn(dim, 4, device='cuda')
out = causal_conv1d_hip_fn(x, weight, bias)
```

### æ¿€æ´»å‡½æ•°

```python
# æ— æ¿€æ´»å‡½æ•°
out = causal_conv1d_hip_fn(x, weight, bias, activation=None)

# SiLU æ¿€æ´»
out = causal_conv1d_hip_fn(x, weight, bias, activation='silu')

# Swish æ¿€æ´»ï¼ˆç­‰åŒäº SiLUï¼‰
out = causal_conv1d_hip_fn(x, weight, bias, activation='swish')
```

### å¯é€‰ Bias

```python
# å¸¦ bias
out = causal_conv1d_hip_fn(x, weight, bias, activation='silu')

# ä¸å¸¦ bias
out = causal_conv1d_hip_fn(x, weight, None, activation='silu')
```

## ğŸ§ª æµ‹è¯•å’ŒéªŒè¯

### è¿è¡Œå†…ç½®æµ‹è¯•

```python
from causal_conv1d_hip_interface import test_causal_conv1d_hip
test_causal_conv1d_hip()
```

### ä¸å‚è€ƒå®ç°å¯¹æ¯”

```python
from causal_conv1d_hip_interface import (
    causal_conv1d_hip_fn,
    causal_conv1d_hip_ref
)

# HIP å®ç°
out_hip = causal_conv1d_hip_fn(x, weight, bias, activation='silu')

# PyTorch å‚è€ƒå®ç°
out_ref = causal_conv1d_hip_ref(x, weight, bias, activation='silu')

# éªŒè¯ç²¾åº¦
diff = (out_hip - out_ref).abs()
print(f"Max diff: {diff.max().item():.6f}")
assert diff.max() < 1e-3, "Accuracy check failed"
```

## ğŸ¯ æ€§èƒ½ä¼˜åŒ–å»ºè®®

1. **ä½¿ç”¨è¿ç»­å†…å­˜**: ç¡®ä¿è¾“å…¥å¼ é‡æ˜¯è¿ç»­çš„
   ```python
   x = x.contiguous()
   ```

2. **é¢„åˆ†é…è¾“å‡º**: é¿å…å†…å­˜åˆ†é…å¼€é”€ï¼ˆå½“å‰ç‰ˆæœ¬è‡ªåŠ¨å¤„ç†ï¼‰

3. **æ‰¹å¤„ç†**: å¢åŠ  batch size æé«˜ GPU åˆ©ç”¨ç‡
   ```python
   # å¥½ï¼šbatch_size = 8
   x = torch.randn(8, 128, 2048, device='cuda')
   
   # ä¸å¥½ï¼šbatch_size = 1
   x = torch.randn(1, 128, 2048, device='cuda')
   ```

4. **é€‰æ‹©åˆé€‚çš„ç»´åº¦**: dim åº”è¯¥æ˜¯ 32 çš„å€æ•°ä»¥è·å¾—æœ€ä½³æ€§èƒ½
   ```python
   # æ¨è
   dim = 64, 128, 256, 512
   
   # ä¸æ¨è
   dim = 63, 127, 255
   ```

## ğŸ› å¸¸è§é—®é¢˜

### Q: ç¼–è¯‘å¤±è´¥ï¼Œæ‰¾ä¸åˆ° hipcc

**A**: è®¾ç½® ROCm è·¯å¾„
```bash
export PATH=/opt/rocm/bin:$PATH
export ROCM_PATH=/opt/rocm
```

### Q: è¿è¡Œæ—¶æ‰¾ä¸åˆ°æ‰©å±•æ¨¡å—

**A**: è®¾ç½® Python è·¯å¾„
```bash
export PYTHONPATH=/workspace/causal-conv1d/rocm_backend/hip_backend/fwd/build:$PYTHONPATH
```

### Q: ç²¾åº¦ä¸åŒ¹é…

**A**: æ£€æŸ¥æ•°æ®ç±»å‹å’Œè®¾å¤‡
```python
assert x.dtype == torch.float32, "Only float32 supported"
assert x.device.type == 'cuda', "Must be on HIP device"
```

### Q: æ€§èƒ½ä¸å¦‚é¢„æœŸ

**A**: æ£€æŸ¥é…ç½®
```python
# 1. å¢åŠ  batch size
# 2. ä½¿ç”¨æ›´å¤§çš„ dimï¼ˆ128, 256, 512ï¼‰
# 3. ç¡®ä¿æ•°æ®æ˜¯è¿ç»­çš„
x = x.contiguous()
```

## ğŸ“š æ›´å¤šèµ„æº

- **å®Œæ•´æ–‡æ¡£**: `HIP_INTEGRATION_README.md`
- **ç¤ºä¾‹ä»£ç **: `example_usage.py`
- **å†…æ ¸å®ç°**: `causal_conv1d_kernel.hip`
- **æµ‹è¯•è„šæœ¬**: `causal_conv1d_hip_interface.py`

## ğŸ’¡ ä¸‹ä¸€æ­¥

1. é˜…è¯»å®Œæ•´æ–‡æ¡£ï¼š`cat HIP_INTEGRATION_README.md`
2. è¿è¡Œç¤ºä¾‹ï¼š`python3 example_usage.py`
3. é›†æˆåˆ°è‡ªå·±çš„é¡¹ç›®
4. è´¡çŒ®ä»£ç ï¼šå®ç° backwardã€FP16 æ”¯æŒç­‰

